{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5b81e7c-ccf2-4293-b07f-fa05539bb44d",
   "metadata": {},
   "source": [
    "# Learn PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12dfad04-e887-4224-84a6-860871c82374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/ismail/ismail/myenv/lib/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in /home/ismail/ismail/myenv/lib/python3.12/site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in /home/ismail/ismail/myenv/lib/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0884a96f-27a7-406c-a38a-73221c24ae4e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Stage 1 : üî• Stage 1: PyTorch Tensors (Your First Building Block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0547a226-8392-4d79-970a-aef8ca614327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "212a58da-bde5-4f5f-a356-a59463275d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f0bf150-6f3d-4354-b70a-df40110881c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6859, 0.0032, 0.4774],\n",
       "        [0.5443, 0.4900, 0.6425]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "306f76ab-a842-4b0f-9ee7-8a53c62850f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13b98778-5507-489b-b509-93a9ab22d8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcacd768-9f8d-4096-8995-b38380da15d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 1.2500, 2.5000, 3.7500, 5.0000])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(0,5,steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80e92944-e6cf-4e6f-88bf-576ca78013ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 7., 9.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1., 2., 3.])\n",
    "y = torch.tensor([4., 5., 6.])\n",
    "x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba499c85-69fd-431b-b286-eaf698da0d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(32.)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix multiplication\n",
    "x@y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e00f349-adba-4487-9ad3-36f6698b5fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [2.],\n",
       "        [3.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8aed6da1-c408-44e1-958c-a8aec139f3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [2.],\n",
       "        [3.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e51ca283-b705-4c7c-9123-4ee67082e2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  3.,  4.],\n",
       "        [ 5.,  6.,  7.],\n",
       "        [ 8.,  9., 10.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a tensor of ones on 3 by 3 tensor\n",
    "tensor_3_by_3 = torch.tensor([\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9]\n",
    "])\n",
    "ones = torch.ones(3,3)\n",
    "addition= tensor_3_by_3 + ones\n",
    "addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec9e9d96-33c6-465e-a7c1-e8555b011557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  6.,  8.],\n",
       "        [10., 12., 14.],\n",
       "        [16., 18., 20.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply by 2\n",
    "multiplication_by_2 = addition *2\n",
    "multiplication_by_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fd1fc01-be2b-487e-b162-a954c8260775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  6.,  8., 10., 12., 14., 16., 18., 20.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshape_1_9 = multiplication_by_2.reshape(1,9)\n",
    "reshape_1_9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebc5e88-a0f4-4a88-85ec-b899da551464",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Stage 2 : Autograde Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8c7ea22-5d99-43d0-b17f-f9c3901ff57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = x**2 + 3*x+5\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "332e14e4-591c-411f-bad9-42b901a505ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a490e6d4-5926-4e08-afde-ab4530edb610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81cdd57b-402f-49f8-969e-5bc8c003f58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 4., 6.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "y = (x ** 2).sum()   # y = x1^2 + x2^2 + x3^2\n",
    "y.backward()\n",
    "\n",
    "print(x.grad)  # tensor([2., 4., 6.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d3d000d-72c9-4aae-9ac1-5ef2f8294b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Stopping gradient\n",
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "y = x ** 2\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = y * 2   # no gradient tracking here\n",
    "\n",
    "print(z.requires_grad)  # False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40c52857-8f97-4a8b-8c23-703ba13cdbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.)\n",
      "tensor(3.)\n",
      "tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "# Clear old gradient\n",
    "w = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "for i in range(3):\n",
    "    y = w * 3\n",
    "    y.backward()\n",
    "    print(w.grad)  # gradients accumulate!\n",
    "\n",
    "    w.grad.zero_()  # reset gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fe477b9-e442-4921-ac0d-5fe0f7fe0968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(160.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(4.0, requires_grad=True)\n",
    "y = 3*x**3 + 2*x**2 + 7\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634be1a5-ab55-4d9f-a2ff-d4ef0d6b7a44",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## üî• Stage 3: Neural Networks with nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7d279e5-2636-47d8-850b-a41fc533a942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearModel(\n",
      "  (linear): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define model\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1)  # input size=1, output size=1\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Create model\n",
    "model = LinearModel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "461651f2-51f7-4877-8bbe-819030a83f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.4968]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[2.0]])   # input (batch_size=1, features=1)\n",
    "y_pred = model(x)           # forward pass\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b4e1b12-3b9c-4500-8b88-552534d98c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True data\n",
    "X = torch.tensor([[1.0], [2.0], [3.0], [4.0]])\n",
    "Y = torch.tensor([[3.0], [5.0], [7.0], [9.0]])\n",
    "\n",
    "# Model\n",
    "model = LinearModel()\n",
    "\n",
    "# Loss function (Mean Squared Error)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Optimizer (Stochastic Gradient Descent)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e49a981f-085c-45c1-8d23-e7083a19bdbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Loss: 0.1091\n",
      "Epoch 100, Loss: 0.0809\n",
      "Epoch 150, Loss: 0.0599\n",
      "Epoch 200, Loss: 0.0444\n",
      "Epoch 250, Loss: 0.0329\n",
      "Epoch 300, Loss: 0.0244\n",
      "Epoch 350, Loss: 0.0181\n",
      "Epoch 400, Loss: 0.0134\n",
      "Epoch 450, Loss: 0.0099\n",
      "Epoch 500, Loss: 0.0073\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(500):\n",
    "    # Forward pass\n",
    "    Y_pred = model(X)\n",
    "    loss = criterion(Y_pred, Y)\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce6ec6c3-0dae-4112-b6ed-7ce7c6ac09a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for x=5: 11.146489143371582\n"
     ]
    }
   ],
   "source": [
    "x_test = torch.tensor([[5.0]])\n",
    "y_test = model(x_test)\n",
    "print(\"Prediction for x=5:\", y_test.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08121bcd-492a-4342-aaa6-f586db5b6091",
   "metadata": {},
   "source": [
    "## üî• Stage 4: Loss Functions & Optimizers in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a752112-db7b-484d-9a11-eb3d917f584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, Y)\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()  # reset old gradients\n",
    "    loss.backward()        # compute new gradients\n",
    "    optimizer.step()       # update weights\n",
    "\n",
    "    # print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bea8f20-05f7-4434-bf29-14f666c8371f",
   "metadata": {},
   "source": [
    "grad vs zero_grad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c66779e-7dca-4a4d-8d69-01d77f285545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Loss: 0.5442\n",
      "Epoch 100, Loss: 0.4602\n",
      "Epoch 150, Loss: 0.3996\n",
      "Epoch 200, Loss: 0.3546\n",
      "Prediction for 1.5 hours: 0.3603784739971161\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Data: [hours studied], label [pass/fail]\n",
    "X = torch.tensor([[1.0], [2.0], [3.0], [4.0]])\n",
    "Y = torch.tensor([[0.0], [0.0], [1.0], [1.0]])\n",
    "\n",
    "# Model: simple linear classifier\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(1, 1),\n",
    "    nn.Sigmoid()   # squash output between 0 and 1\n",
    ")\n",
    "\n",
    "# Loss & Optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(200):\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, Y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')\n",
    "\n",
    "# Test\n",
    "print(\"Prediction for 1.5 hours:\", model(torch.tensor([[1.5]])).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bece92b4-09f4-4bdb-ad02-987f58fe9b22",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## üéØ Stage 5: Training a Full Model (Putting it All Together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc7eb5d6-6bd7-4176-bde1-cb8c546b5244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7087\n",
      "Epoch 2, Loss: 0.5915\n",
      "Epoch 3, Loss: 0.6551\n",
      "Epoch 4, Loss: 0.4581\n",
      "Epoch 5, Loss: 0.5864\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Fake dataset (100 samples, 10 features each, 2 classes)\n",
    "X = torch.randn(100, 10)\n",
    "y = torch.randint(0, 2, (100,))\n",
    "\n",
    "# Wrap in DataLoader\n",
    "dataset = TensorDataset(X, y)\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Model (simple feedforward)\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)  # 2 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):\n",
    "    for batch_X, batch_y in loader:\n",
    "        # Forward\n",
    "        preds = model(batch_X)\n",
    "        loss = criterion(preds, batch_y)\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e60f354-1d21-49f3-9db8-688825978b9f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Stage 6: Training on a Real Dataset (MNIST)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d635d845-dd46-40f5-afc0-9d97bfb8ceb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.91M/9.91M [00:30<00:00, 322kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28.9k/28.9k [00:00<00:00, 131kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.65M/1.65M [00:03<00:00, 519kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.54k/4.54k [00:00<00:00, 3.86MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Epoch 1, Loss: 0.8522\n",
      "Epoch 2, Loss: 0.4705\n",
      "Epoch 3, Loss: 0.2051\n",
      "Test Accuracy: 90.15%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. Load Data (with transforms to tensors)\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_data = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=1000)\n",
    "\n",
    "# 2. Define Model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)  # 10 digits (0‚Äì9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)   # Flatten image\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "\n",
    "# 3. Loss & Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 4. Training Loop\n",
    "for epoch in range(3):  # train for 3 epochs\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        # Forward\n",
    "        preds = model(batch_X)\n",
    "        loss = criterion(preds, batch_y)\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# 5. Testing Loop (evaluation)\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        preds = model(batch_X)\n",
    "        predicted = preds.argmax(dim=1)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69ed2db-1b32-4994-8da0-d4fc033b0dc6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Stage 7: Convolutional Neural Networks (CNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55b8c7a4-f190-4979-8239-02788606aca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0419\n",
      "Epoch 2, Loss: 0.0100\n",
      "Epoch 3, Loss: 0.0307\n",
      "Test Accuracy: 98.71%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. Data\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_data = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=1000)\n",
    "\n",
    "# 2. CNN Model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)  # 1 input channel (grayscale), 32 filters\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3) # 64 filters\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # 2x2 max pooling\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 12 * 12, 128)  # after conv+pool, image size reduces\n",
    "        self.fc2 = nn.Linear(128, 10)            # 10 classes (digits)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))   # [batch, 32, 26, 26]\n",
    "        x = self.pool(torch.relu(self.conv2(x)))  # [batch, 64, 12, 12]\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, 64 * 12 * 12)    # Flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = CNN()\n",
    "\n",
    "# 3. Loss & Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam usually faster than SGD\n",
    "\n",
    "# 4. Training Loop\n",
    "for epoch in range(3):\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        preds = model(batch_X)\n",
    "        loss = criterion(preds, batch_y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# 5. Testing\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        preds = model(batch_X)\n",
    "        predicted = preds.argmax(dim=1)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a125f3e-6108-42af-8988-cee22c2f62f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Stage 8: Training on GPU (CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b732bf9b-8dd3-4e63-a885-a2d61e8cc521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())   # True if CUDA is installed\n",
    "print(torch.cuda.device_count())   # Number of GPUs\n",
    "# print(torch.cuda.get_device_name(0))  # GPU name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6fe536e3-9e44-4c29-831a-a3f4e9d15eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df414a21-3061-4799-85e8-7104ffeb8303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.3073\n",
      "Epoch 2, Loss: 2.3036\n",
      "Epoch 3, Loss: 2.3054\n"
     ]
    }
   ],
   "source": [
    "model = CNN().to(device)\n",
    "\n",
    "for epoch in range(3):\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)  # move data\n",
    "\n",
    "        preds = model(batch_X)\n",
    "        loss = criterion(preds, batch_y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a96499b-dd77-482c-8bff-ee6267ab4f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 9.67%\n"
     ]
    }
   ],
   "source": [
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        preds = model(batch_X)\n",
    "        predicted = preds.argmax(dim=1)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cb8246-1178-47c9-ab77-0518c28d3ce5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Stage 9: Saving & Loading Models in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8be8f9a3-96bd-42e2-b3fa-19cd503cc00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d623d395-cc1c-4433-945b-949620ab731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_state.pth\") # Recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "44c53863-8da0-4618-8f98-41585c9af8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10384/3976716716.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(\"model.pth\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"model.pth\")\n",
    "model.eval()  # set to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "07494f71-bd45-4e16-8b0c-1b2eb3e1e24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10384/50389116.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"model_state.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recommended\n",
    "model = Net()  # re-initialize the same architecture\n",
    "model.load_state_dict(torch.load(\"model_state.pth\"))\n",
    "model.eval()   # evaluation mode (turns off dropout, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b95b5ec-223e-4854-8842-3f9547b5a629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save optimizer state\n",
    "torch.save({\n",
    "    \"epoch\": epoch,\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"optimizer_state\": optimizer.state_dict(),\n",
    "    \"loss\": loss,\n",
    "}, \"checkpoint.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e2e33330-9c26-44d6-adb9-ff6a2e28387c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10384/2088388649.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"checkpoint.pth\")\n"
     ]
    }
   ],
   "source": [
    "# Load optimizer state\n",
    "checkpoint = torch.load(\"checkpoint.pth\")\n",
    "model.load_state_dict(checkpoint[\"model_state\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "epoch = checkpoint[\"epoch\"]\n",
    "loss = checkpoint[\"loss\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88bdf24-08c1-4237-a313-ee0eec0690c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## üîπ Stage 10: PyTorch Lightning & Accelerators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c1b72da3-af0e-4444-99ab-4ad1eee2b933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-2.5.5-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: torch>=2.1.0 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from pytorch-lightning) (2.5.1)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from pytorch-lightning) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>5.4 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from pytorch-lightning) (6.0.2)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.10.0)\n",
      "Collecting torchmetrics>0.7.0 (from pytorch-lightning)\n",
      "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from pytorch-lightning) (24.2)\n",
      "Requirement already satisfied: typing-extensions>4.5.0 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from pytorch-lightning) (4.12.2)\n",
      "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n",
      "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.11.11)\n",
      "Requirement already satisfied: setuptools in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.6.0)\n",
      "Requirement already satisfied: filelock in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (3.17.0)\n",
      "Requirement already satisfied: networkx in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from torchmetrics>0.7.0->pytorch-lightning) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.18.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.2)\n",
      "Requirement already satisfied: idna>=2.0 in /home/ismail/ismail/myenv/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.10)\n",
      "Downloading pytorch_lightning-2.5.5-py3-none-any.whl (832 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
      "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "Installing collected packages: lightning-utilities, torchmetrics, pytorch-lightning\n",
      "Successfully installed lightning-utilities-0.15.2 pytorch-lightning-2.5.5 torchmetrics-1.8.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ce940c32-22cf-42a2-85c1-be7595cd522b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.5\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "print(pl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e4ea0c14-a5d7-430d-9adc-5c08806683f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025-10-06 16:42:04.805004: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759749124.975683   10384 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1759749125.022928   10384 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1759749125.280327   10384 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759749125.280400   10384 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759749125.280407   10384 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759749125.280411   10384 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-10-06 16:42:05.315589: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\n",
      "  | Name | Type   | Params | Mode \n",
      "----------------------------------------\n",
      "0 | fc1  | Linear | 100 K  | train\n",
      "1 | fc2  | Linear | 8.3 K  | train\n",
      "2 | fc3  | Linear | 650    | train\n",
      "----------------------------------------\n",
      "109 K     Trainable params\n",
      "0         Non-trainable params\n",
      "109 K     Total params\n",
      "0.438     Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/ismail/ismail/myenv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ff402b80fa4b329ba0d3c4e28c72cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# 1. Define Lightning Module\n",
    "class LitNet(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self(x)\n",
    "        loss = F.cross_entropy(preds, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD(self.parameters(), lr=0.01)\n",
    "\n",
    "# 2. Data\n",
    "transform = transforms.ToTensor()\n",
    "train_data = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "\n",
    "# 3. Train\n",
    "model = LitNet()\n",
    "trainer = pl.Trainer(max_epochs=3, accelerator=\"auto\")\n",
    "trainer.fit(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b9c37bfb-8c3f-4704-a02b-a009765a5edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = pl.Trainer(max_epochs=3, accelerator=\"gpu\", devices=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "10dba0a7-ec6e-4014-9ebd-82fa8ab9eb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = pl.Trainer(max_epochs=3, accelerator=\"gpu\", devices=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3b6d6d-919b-4d74-b187-61e7139bc5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
